{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Probability\n",
    "\n",
    "Ryan Henning's lecture is based on those by Adam Richards, Tammy Lee, Lee Murray, Scott Schwartz, Matthew Drury, and other Galvanize folks.\n",
    "\n",
    "\n",
    "**Afternoon**:\n",
    "* Introduce expected value, variance, covariance, and correlation.\n",
    "* Discuss why correlation is not causation! Reference xkcd and Anscombe's Quartet.\n",
    "* Differentiate between discrete and continuous (random) variables.\n",
    "* Major probability distributions\n",
    "    * Discrete: Bernoulli, Binomial, Geometric, Poisson\n",
    "    * Continuous: Uniform, Normal, Exponential\n",
    "* Define Joint Probability Distributions\n",
    "* Define Marginalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Expected Value\n",
    "$$E(X) = \\sum_{s \\in S} s * P(X=s)$$\n",
    "\n",
    "It is the possible outcomes weighted by their respective probabilities of occurring.\n",
    "\n",
    "Intuition: the expectation is the average of infinite samples taken from a population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variance\n",
    "\n",
    "It is the expected value of $(X-E(X))^2$.\n",
    "\n",
    "$$Var(X) = \\sum_{s \\in S} (s-E(X))^2 * P(X=s)$$\n",
    "\n",
    "Variance quantifies the amount of \"spread\" in the possible outcomes.\n",
    "\n",
    "The standard deviation is the square root of the variance.\n",
    "\n",
    "<br><font color='red'><center>Why might the standard deviation be more useful than variance when talking about data?</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Covariance and Correlation\n",
    "\n",
    "Covariance quantifies the amount two variables are linearly associated, in the scale of the square of those units (this last part makes it hard to interpret).  If two variables are independent, their covariance is 0.\n",
    "\n",
    "Covariance is the expected value of $(X - E(X))(Y - E(Y))$.\n",
    "\n",
    "$$Cov(X, Y) = \\dfrac{\\sum_{i = 1}^n (X_i - E(X))(Y_i - E(Y))} {n-1}$$\n",
    "\n",
    "Correlation is covariance normalized by the standard deviations of $X$ and $Y$, on a scale from -1 (perfectly negatively corrlated) to 0 (no correlation) to +1 (perfectly positively correlated).\n",
    "\n",
    "$$Corr(X, Y) = \\dfrac{\\sum_{i = 1}^n (X_i - E(X))(Y_i - E(Y))} {\\sqrt{ \\sum_{i=1}^n (X_i - E(X))^2  \\sum_{i=1}^n (Y_i - E(Y))^2 }}$$\n",
    "\n",
    "The correlation coefficient $r$ reflects:\n",
    "* noisiness and direction (line 1)\n",
    "* but not slope (line 2)\n",
    "* and not other non-linearities (line 3)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/d/d4/Correlation_examples2.svg)\n",
    "\n",
    "\n",
    "\n",
    "<br><font color='red'><center>In the last line, all linear correlations are 0.  Does that mean the x and y values are independent?</center></font><br><br><br>\n",
    "\n",
    "The coefficient of determination $r^2$ is the square of the correlation coefficient and ranges from [0, 1].\n",
    "\n",
    "### Correlation Does not Imply Causation\n",
    "\n",
    "![](https://imgs.xkcd.com/comics/correlation.png)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## So summary statistics are all we need, right?  No need to look at the data...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "See: https://en.wikipedia.org/wiki/Anscombe%27s_quartet\n",
    "\n",
    "Summary statistics are dangerous and nothing can replace actually plotting the data.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array, amin, amax\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def fit(x):\n",
    "    return 3+0.5*x\n",
    "\n",
    "\n",
    "def anscombe():\n",
    "    x =  array([10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5])\n",
    "    y1 = array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "    y2 = array([9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74])\n",
    "    y3 = array([7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73])\n",
    "    x4 = array([8,8,8,8,8,8,8,19,8,8,8])\n",
    "    y4 = array([6.58,5.76,7.71,8.84,8.47,7.04,5.25,12.50,5.56,7.91,6.89])\n",
    "\n",
    "    xfit = array( [amin(x), amax(x) ] )\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(221)\n",
    "    plt.plot(x,y1,'ks', xfit, fit(xfit), 'r-', lw=2)\n",
    "    plt.axis([2,20,2,14])\n",
    "    plt.setp(plt.gca(), xticklabels=[], yticks=(4,8,12), xticks=(0,10,20))\n",
    "    plt.text(3,12, 'I', fontsize=20)\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.plot(x,y2,'ks', xfit, fit(xfit), 'r-', lw=2)\n",
    "    plt.axis([2,20,2,14])\n",
    "    plt.setp(plt.gca(), xticklabels=[], yticks=(4,8,12), yticklabels=[], xticks=(0,10,20))\n",
    "    plt.text(3,12, 'II', fontsize=20)\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.plot(x,y3,'ks', xfit, fit(xfit), 'r-', lw=2)\n",
    "    plt.axis([2,20,2,14])\n",
    "    plt.text(3,12, 'III', fontsize=20)\n",
    "    plt.setp(plt.gca(), yticks=(4,8,12), xticks=(0,10,20))\n",
    "\n",
    "    xfit = array([amin(x4),amax(x4)])\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.plot(x4,y4,'ks', xfit, fit(xfit), 'r-', lw=2)\n",
    "    plt.axis([2,20,2,14])\n",
    "    plt.setp(plt.gca(), yticklabels=[], yticks=(4,8,12), xticks=(0,10,20))\n",
    "    plt.text(3,12, 'IV', fontsize=20)\n",
    "\n",
    "    pairs = (x,y1), (x,y2), (x,y3), (x4,y4)\n",
    "    for x,y in pairs:\n",
    "        print ('mean=%1.2f, std=%1.2f, r=%1.2f'%(np.mean(y), np.std(y), np.corrcoef(x,y)[0][1]))\n",
    "\n",
    "anscombe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Overall, problems with only seeing the correlation:\n",
    "\n",
    "1. It only captures linear relationship, not other relationships.\n",
    "2. It doesn't capture slope at all; it only captures linear relationships (minus noise).\n",
    "3. There are many dataset which have the same correlation even though they are way different.\n",
    "\n",
    "### You can't replace the power of just plotting the data and looking at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Continuous vs Discrete (Random) Variables\n",
    "\n",
    "All above, we only talked about _discrete_ random variables (although we didn't use that term until now). However, a random variable (or a variable in general) need not be discrete. Here's the difference between _discrete_ and _continuous_: [ref](https://en.wikipedia.org/wiki/Continuous_and_discrete_variables)\n",
    "\n",
    "**Discrete**: there is a positive, minimum difference between two values the variable can take\n",
    "\n",
    "**Continuous**: between two values the variable can take, there are uncountably infinite other values the variable can take\n",
    "\n",
    "Another way to put it: There are measurable \"gaps\" between value of a discrete variable, where the gaps between values of a continuous variable can be made infinitesimal.\n",
    "\n",
    "### Probability Mass Function (PMF)\n",
    "\n",
    "The PMF of a r.v. $X$ gives the probabilities of every outcome in the support $S$ of r.v. $X$. For example:\n",
    "\n",
    "<img src=\"images/pmf.png\" width=400px>\n",
    "\n",
    "<br><font color='red'><center>Draw a PMF for a single random variable $X$ that is the sum of two 6-sided dice?</center></font>\n",
    "\n",
    "### Probability Density Function (PDF)\n",
    "\n",
    "The PDF of a r.v. $X$ gives the relative likelihood of a random variable's support. PDFs should not be interpreted the same as a PMF; with a PDF you only can interpret area-under-the-curve.\n",
    "\n",
    "<img src=\"images/pdf.png\" width=400px>\n",
    "\n",
    "<br><font color='red'><center>What is the probability that I sample the r.v. and get exactly 0.0?<br>I.e. $P(X=0.0)=$ ???</center></font>\n",
    "\n",
    "### Recall: Expectation and Variance\n",
    "\n",
    "For **discrete** random variables (let $P$ be the PMF of the r.v. $X$):\n",
    "\n",
    "$$E(X) = \\sum_{s \\in S} s * P(X=s)$$\n",
    "\n",
    "$$Var(X) = \\sum_{s \\in S} (s-E(X))^2 * P(X=s)$$\n",
    "\n",
    "For **continuous** random variables (let $f$ is the PDF of r.v. $X$):\n",
    "\n",
    "$$E(X) = \\int_{x=-\\infty}^{\\infty} x * f(x) dx$$\n",
    "\n",
    "$$Var(X) = \\int_{x=-\\infty}^{\\infty} (x-E(X))^2 * f(x) dx$$\n",
    "\n",
    "___\n",
    "\n",
    "<font color='red'><center>What is the difference between $E(X)$ and the mean of $X$?</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Major Probability Distributions\n",
    "\n",
    "All you need to build a distribution is a PMF (if discrete) or a PDF (if continuous), and define the support. For it to be legit, the PMF must be non-negative and sum to 1 over the support.\n",
    "\n",
    "Next, you derive the mean and variance using the PMF (or PDF), the support, and the definition of mean and variance. See [this](http://filestore.aqa.org.uk/subjects/AQA-MS03-W-2-SM.PDF) (or this [local copy](misc/AQA-MS03-W-2-SM.PDF)) for a derivation of the mean and variance for all the distributions below.\n",
    "\n",
    "### Discrete Distributions:\n",
    "\n",
    "#### Bernoulli\n",
    "\n",
    "$X \\sim \\text{Bernoulli}(p)$:  \n",
    "A single coin flip turns up heads with probability $p$.\n",
    "\n",
    "PMF: $P[success] = p$ , $P[failure] = 1-p$\n",
    "\n",
    "Support: $\\{\\text{success}, \\text{failure}\\}$\n",
    "\n",
    "Mean: $p$\n",
    "\n",
    "Variance: $p (1-p)$\n",
    "\n",
    "<img src=\"images/bernoulli.png\" width=400px>\n",
    "\n",
    "#### Binomial\n",
    "\n",
    "$X \\sim \\text{Binomial}(n, p)$:  \n",
    "The number of coin flips out of n which turn up heads. $p$ is the probability of heads for each trial.\n",
    "\n",
    "PMF: $P[X=k] = {n \\choose k} p^k (1-p)^{n-k}$\n",
    "\n",
    "Support: $k \\in \\{0,1,...,n\\}$\n",
    "\n",
    "Mean: $np$\n",
    "\n",
    "Variance: $np(1-p)$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/75/Binomial_distribution_pmf.svg\" width=400px>\n",
    "\n",
    "#### Geometric\n",
    "\n",
    "$X \\sim \\text{Geometric}(p)$:  \n",
    "The number of trials until a coin flip turns up heads.\n",
    "\n",
    "PMF: $P[X=k] = p(1-p)^{k-1}$\n",
    "\n",
    "Support: $k \\in \\{0,1,...\\}$\n",
    "\n",
    "Mean: $\\frac{1}{p}$\n",
    "\n",
    "Variance: $\\frac{1-p}{p^2}$\n",
    "\n",
    "<img src=\"images/geometric.png\" width=400px>\n",
    "\n",
    "#### Poisson\n",
    "\n",
    "$X \\sim \\text{Poisson}(\\lambda)$:  \n",
    "The number of taxis passing a street corner in a given hour (on avg, 10/hr, so $\\lambda=10$).\n",
    "\n",
    "PMF: $P[X=k] = \\frac{ \\lambda^k e^{-\\lambda} }{ k! }$\n",
    "\n",
    "Support: $k \\in \\{0,1,2,...\\}$\n",
    "\n",
    "Mean: $\\lambda$\n",
    "\n",
    "Variance: $\\lambda$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/16/Poisson_pmf.svg\" width=400px>\n",
    "\n",
    "This is a good time to mention the [Gambler's fallacy](https://en.wikipedia.org/wiki/Gambler%27s_fallacy). Does the Poisson distribution disagree with the fallacy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Continuous Distributions:\n",
    "\n",
    "#### Uniform\n",
    "\n",
    "$X \\sim \\text{Uniform}(a, b)$:  \n",
    "Degrees between hour hand and minute hand ($a=0, b=360$).\n",
    "\n",
    "PDF: $f(x) = \\frac{1}{b-a}$\n",
    "\n",
    "Support: $x \\in [a, b]$\n",
    "\n",
    "Mean: $\\frac{a+b}{2}$\n",
    "\n",
    "Variance: $\\frac{(b-a)^2}{2}$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/96/Uniform_Distribution_PDF_SVG.svg\" width=400px>\n",
    "\n",
    "#### Normal (a.k.a., Gaussian)\n",
    "\n",
    "$X \\sim \\text{Gaussian}(\\mu, \\sigma)$:  \n",
    "IQ Scores (if $\\mu = 100, \\sigma = 10$)\n",
    "\n",
    "PDF: $f(x) = \\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} } \\exp(- \\frac{ (x-\\mu)^2 }{ 2 \\sigma^2 })$\n",
    "\n",
    "Support: $x \\in (-\\infty, \\infty)$\n",
    "\n",
    "Mean: $\\mu$\n",
    "\n",
    "Variance: $\\sigma^2$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/74/Normal_Distribution_PDF.svg\" width=400px>\n",
    "\n",
    "#### Exponential\n",
    "\n",
    "$X \\sim \\text{Exponential}(\\lambda)$:  \n",
    "Number of minutes until a taxi will pass street corner (if on average 10 taxis pass per hour; $\\lambda=10/60$ the number of taxis per minute)\n",
    "\n",
    "CDF: $f(x) = \\lambda \\exp(\\lambda x)$\n",
    "\n",
    "Support: $x \\in [0, \\infty)$\n",
    "\n",
    "Mean: $\\frac{1}{\\lambda}$\n",
    "\n",
    "Variance: $\\frac{1}{\\lambda^2}$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ec/Exponential_pdf.svg\" width=400px>  \n",
    "\n",
    "\n",
    "#### And there are more:\n",
    "http://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Example using scipy.stats\n",
    "\n",
    "Let's say we have 100 products in a box where the probability of each product being defective is 5%.  What is the probability of the box containing 3 defective products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as scs\n",
    "\n",
    "# this is a binomial distribution where each \"success\" is a failure governed by p = 5%.\n",
    "\n",
    "n, p, k = 100, 0.05, 3  # n total number of products, p = probability of failure, k = number of failures\n",
    "prob = scs.binom.pmf(k, n, p, loc = 0) \n",
    "print(\"The probability the box contains {0} failures is = {1:0.3f}.\".format(k,prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Joint Probability Distribution\n",
    "\n",
    "The probability of pairs of events from two (or more) random variables:\n",
    "\n",
    "$$P(A=a, B=b)$$\n",
    "\n",
    "If two random variables, also called a __bivariate distribution__ or if more random variables, called a __multivariate distribution__.\n",
    "\n",
    "Always true:\n",
    "\n",
    "$$P(A=a, B=b) = P(A=a | B=b) * P(B=b)$$\n",
    "\n",
    "If independent:\n",
    "\n",
    "$$P(A=a, B=b) = P(A=a) * P(B=b)$$\n",
    "\n",
    "Always (if discrete):\n",
    "\n",
    "$$1 = \\sum_{a \\in S_A} \\sum_{b \\in S_B} P(A=a, B=b)$$\n",
    "\n",
    "Always (if continuous):\n",
    "\n",
    "$$1 = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(a, b) \\, da \\, db$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Marginalization\n",
    "\n",
    "Marginalization takes a (possibly _dependent_) multivariate distribution and considers only a single variable using the _Law of Total Probability_.\n",
    "\n",
    "Accomplished by summing (if discrete) or integrating (if continuous).\n",
    "\n",
    "**If continuous:**\n",
    "\n",
    "$$f_X(x) = \\int_{-\\infty}^\\infty f_{XY}(x,s) ds$$\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/8e/MultivariateNormal.png)\n",
    "\n",
    "**If discrete:**\n",
    "\n",
    "$$P(X) = \\sum_{y \\in S_Y} P(X, Y=y)$$\n",
    "\n",
    "||x1|x2|x3|x4|py(Y)|\n",
    "|---|---|---|---|---|\n",
    "|**y1**|$\\frac{4}{32}$|$\\frac{2}{32}$|$\\frac{1}{32}$|$\\frac{1}{32}$|$\\frac{8}{32}$|\n",
    "|**y2**|$\\frac{2}{32}$|$\\frac{4}{32}$|$\\frac{1}{32}$|$\\frac{1}{32}$|$\\frac{8}{32}$|\n",
    "|**y3**|$\\frac{2}{32}$|$\\frac{2}{32}$|$\\frac{2}{32}$|$\\frac{2}{32}$|$\\frac{8}{32}$|\n",
    "|**y4**|$\\frac{8}{32}$|0|0|0|$\\frac{8}{32}$|\n",
    "|**px(X)**|$\\frac{16}{32}$|$\\frac{8}{32}$|$\\frac{4}{32}$|$\\frac{4}{32}$|1|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
